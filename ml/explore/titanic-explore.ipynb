{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name='us-east-1')\n",
    "sagemaker_client = boto_session.client(service_name='sagemaker', region_name='us-east-1')\n",
    "featurestore_runtime = boto_session.client(service_name='sagemaker-featurestore-runtime', region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_session = Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_featurestore_runtime_client=featurestore_runtime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group_name = \"titanic-features\"\n",
    "titanic_feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=feature_store_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_feature_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_query = titanic_feature_group.athena_query()\n",
    "titanic_table = titanic_query.table_name\n",
    "output_bucket = 'martinig-athena-results-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = f'SELECT * FROM \"sagemaker_featurestore\".\"{titanic_table}\";'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "titanic_query.run(query_string=query_string, output_location='s3://'+output_bucket+'/query_results/')\n",
    "titanic_query.wait()\n",
    "df = titanic_query.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('seaborn-ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(table, legloc='upper right',\n",
    "                                    plt_style = 'seaborn-ticks',\n",
    "                                    color_palette=\"dark\",sorter=None, stacked=False,\n",
    "                                    kind = 'bar', percentage = True,\n",
    "                               custom_title=None, minimal=True, figsize=(19,10), width=0.7 ):     \n",
    "    grouped = table\n",
    "    \n",
    "    #Tranform to percentages\n",
    "    if percentage == True:\n",
    "        grouped = np.round(grouped.divide(grouped['Total'],axis=0)*100,0)\n",
    "    try:   \n",
    "        del grouped['Total']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # rearrange the columns\n",
    "    if sorter:\n",
    "        grouped = grouped[sorter]\n",
    "\n",
    "    plt.style.use(plt_style)\n",
    "    sns.set_palette(sns.color_palette(color_palette))\n",
    "    ax = grouped.plot(kind=kind,stacked=stacked, figsize=figsize, width=width)\n",
    "    _ = plt.setp(ax.get_xticklabels(), rotation=0)  # Rotate labels\n",
    "    plt.legend(loc=legloc) # plot the legend normally\n",
    "    \n",
    "    #annotate the bars\n",
    "    if percentage == True:\n",
    "      for p in ax.patches:\n",
    "            ax.annotate('{}%'.format(int(np.round(p.get_height(),decimals=2))),\n",
    "                                         (p.get_x()+p.get_width()/2.,\n",
    "                                          p.get_height()), ha='center', va='center',\n",
    "                                        xytext=(0, 10), textcoords='offset points')\n",
    "    else:\n",
    "      for p in ax.patches:\n",
    "            ax.annotate(np.round(p.get_height(),decimals=2),\n",
    "                                         (p.get_x()+p.get_width()/2.,\n",
    "                                          p.get_height()), ha='center', va='center',\n",
    "                                        xytext=(0, 10), textcoords='offset points')\n",
    "    if minimal == True:\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        plt.xlabel('')\n",
    "        sns.despine(top=True, right=True, left=True, bottom=False);\n",
    "    else:\n",
    "        pass     \n",
    "    # set custom title    \n",
    "    plt.title(custom_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Groupby_TwoCol_Plot(df, col1, col2, legloc='upper right',\n",
    "                                    plt_style = 'ggplot',\n",
    "                                    color_palette=\"dark\",sorter=None, stacked=False,\n",
    "                                    kind = 'bar', percentage = True,\n",
    "                               custom_title=None, minimal=True, figsize=(14,6), width=0.6):   \n",
    "    \n",
    "    #Group by Placement and Representative and unstack by Placement\n",
    "    grouped = df.groupby([col2,col1]).size().unstack(col2)\n",
    "    \n",
    "    #Make a totals column sort and delete after\n",
    "    grouped['Total'] = grouped.sum(axis=1)\n",
    "    #grouped = grouped.sort_values('Total', ascending = False)\n",
    "   \n",
    "    plot(grouped, legloc=legloc,\n",
    "                                    plt_style = plt_style,\n",
    "                                    color_palette=color_palette,sorter=sorter, stacked=stacked,\n",
    "                                    kind = kind , percentage = percentage,\n",
    "                               custom_title=custom_title, minimal=minimal, figsize=figsize, width=width)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Groupby_TwoCol_Plot(df,\n",
    "                    'survived',\n",
    "                    'sex',\n",
    "                    color_palette=('red','green'),\n",
    "                    plt_style = 'seaborn-ticks',\n",
    "                    custom_title='Proportion of Survived per Sex',\n",
    "                    legloc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_target = ['sex', 'age', 'survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(features_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[features_target[:-1]]\n",
    "Y = train[features_target[-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test[features_target[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(test[features_target[-1:]].values == pred)\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar artefatos\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dos datasets de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'mlopsstack-mlbucket12760f44-1n0o1haje306i'\n",
    "prefix = 'datasets/titanic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_s3(channel, file):\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = prefix + '/' + channel + '/' + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')\n",
    "upload_to_s3('train', 'train.csv')\n",
    "upload_to_s3('test', 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do script de preparação ou usar SageMaker Data Wrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/use-scikit-learn-processing-container.html\n",
    "- https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/data-wrangler-getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do script de treino e inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../train_inference/train_inference.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# inference function\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"extracting arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=100)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "    parser.add_argument(\"--features\", type=str)\n",
    "    parser.add_argument(\"--target\", type=str) \n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target]\n",
    "    y_test = test_df[args.target]\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators, random_state=0, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print acc\n",
    "    print(\"validating model\")\n",
    "    pred = model.predict(X_test)\n",
    "    acc = np.mean(y_test == pred)\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "\n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(\"model persisted at \" + path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../train_inference/train_inference.py --n-estimators 100 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\\n",
    "                   --features 'sex age' \\\n",
    "                   --target 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"train_inference.py\",\n",
    "    source_dir=\"../train_inference\",\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"titanic-scikit\",\n",
    "    metric_definitions=[{\"Name\": \"Accuracy\", \"Regex\": \"Accuracy: ([0-9.]+).*$\"}],\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"features\": \"sex age\",\n",
    "        \"target\": \"survived\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch training job, with asynchronous call\n",
    "sklearn_estimator.fit({\"train\": f\"s3://{bucket}/{prefix}/train/\", \"test\": f\"s3://{bucket}/{prefix}/test/\"}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "predictor = sklearn_estimator.deploy(instance_type='ml.m4.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(test[features_target[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "'''from io import StringIO\n",
    "test_file = io.StringIO()\n",
    "test[features_target[:-1]].to_csv(test_file,header = None, index = None)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import boto3\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName= \"titanic-scikit-2022-11-04-11-50-57-391\",\n",
    "    Body= test_file.getvalue(),\n",
    "    ContentType = 'text/csv')\n",
    "import json\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "print(result)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do script de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/use-scikit-learn-processing-container.html"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
